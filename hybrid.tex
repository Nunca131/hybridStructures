\documentclass{article}

\usepackage{xcolor}
\usepackage{algorithm2e}
\usepackage{algorithmic}
\usepackage{amsmath}


\newcommand{\TODO}[1]{\begingroup\color{red}#1\endgroup}
\newcommand{\NR}[1]{\begingroup\color{orange}#1\endgroup}
\newcommand{\PFS}[1]{\begingroup\color{green}#1\endgroup}



\begin{document}

\title{\TODO{some fancy title}}

\maketitle



\section{R-Metrics} 

In \cite{Prohaska:17a} we introduced R-metrics by means of a simple
iterative scheme starting from a pair of points $\{x,y\}$ with a given
distance $d_{xy}$.  First, an additional point $z$ is inserted as a
``mixture'' of two parents $x$ and $y$ with a mixture ratio $a$. We assume
that the distance of $d_{zu}$ correspondinly is a mixture of $d_{xu}$ and
$d_{yu}$. More precisely, we assume that
\begin{equation} 
\begin{split} 
  d_{zx} & = (1-a)  d_{xy} \\
  d_{zy} & =   a    d_{xy} \\
  d_{zu} & =   a    d_{xu} + (1-a)  d_{yu} \quad\textrm{for all}\ 
                     u\in V\setminus\{ x,y \}
\end{split}
\end{equation} 
Then all points diverge with arbitrary rates, i.e., 
\begin{equation} 
  d_{pq}' = d_{pq} + \delta_p + \delta_q \quad\textrm{for all}\ 
  p,q \in V\cup\{z\} 
\end{equation} 
We say that a metric is an R-metric if it can be constructed in this
manner.


\subsection*{Properties of R-metrics} 


\TODO{It does not seem to be very easy to check whether R-metric are 
totally decomposable or not. There is a reasonably easy 5-point condition
for that, however:

Set 
\begin{equation} 
  \alpha(tu|vw) := 
  \max\left\{ d_{tu}+d_{vw}, d_{tv}+d_{uw}, d_{tw}+d_{vu} \right\} -
             (d_{tu}+d_{vw})
\end{equation} 

Then Thm.6 of \cite{Bandelt:92} states that the metric is \emph{totally
  decomposable} iff and only if for all $t,u,v,w,x\in V$ holds 
\begin{equation} 
  \alpha(tu|vw) \le \alpha(tx|vw)+\alpha(tu|vx)
\end{equation} 

CAN YOU PLEASE CHECK THIS NUMBERICALLY as a first step. If we see that the 
R-metrics are totally decomposable in a large number of randomly generated
examples it will be worth while to show that analytically, presumably by 
proving that our construction the inequality above whenever.
}

\subsection{From Recognition to Approximation} 

In \cite{Prohaska:17a} we described an $O(|V|^5)$ algorithm to recognize 
R-metrics.    




\begin{algorithm}[H]
\caption{Old recognition algorithm for R matrices}
\SetAlgoLined
\For{$\{x,y,z\} \in V$}{
  \For{$\{u,v\} \in V\setminus\{x,y,z\}$}{
   $a_{u,v} := 
   \frac{(d'_{uz}+d'_{vy})-(d'_{vz}+d'_{uy})}{(d'_{ux}+d'_{vy})-(d'_{vx}+d'_{uy})}$\;
  }
  \If{$\forall a_{u,v}: a_{u,v}=a\in [0,1]$}{
   \eIf{$a \neq 0,1$}{
   $\delta_z = \frac{1}{2}(d'_{xz}+d'_{yz}-d'_{xy})$\;
   $d_{xy} =$ \TODO{siehe Gleichung 11}\;
   $\delta_x = d'_{xz} - (1-a) d_{xy} - \delta_z$\;
   $\delta_y = d'_{yz} - a \delta_z$\;
  }{
   \TODO{$a=0,a=1$ what happens then?}\;
  }
  \PFS{$\forall u\in V\setminus\{x,y,z\}$ and $\forall p\in\{x,y\}$ set   
  $d_{up} = d_{pu} -\delta_p$\;
  \TODO{note that $\delta_u=0$ for $u\in V\setminus\{x,y,z\}$}}
  delete row and column $z$ form $D$\;
  }  
}
\end{algorithm}

We note that in each merge step we have $\delta_u=0$ for all $u\in
V\setminus\{x,y,z\}$ 



\begin{algorithm}[H]
\caption{Top level recursion}
 \SetAlgoLined
 \While{$|V|\ge 4$}{ 
   determine best tree-like step $(x,z)\to x$\;
   determine best merge step $(x,z,y)\to(x,y)$\;
   perform the better of tree-like or merge step\;
   remove $z$ from $\mathbf{D}$ and $V$ 
 }
 compute initial tree for $|V|\le 3$ leaves\;
\end{algorithm} 
   
 

\begin{algorithm}[H]
\caption{Approximation recognition algorithm for R matrices}
 \SetAlgoLined
 \For{$\{x,y,z\} \in V$}{
  \For{$\{u,v\} \in V\setminus\{x,y,z\}$}{
   $a_{u,v} := \frac{(d'_{uz}+d'_{vy})-(d'_{vz}+d'_{uy})}{(d'_{ux}+d'_{vy})-(d'_{vx}+d'_{uy})}$\;
  }
  $\bar{a}_{xyz} = \frac{2}{(n-3)(n-4)} * a_{uv}$\;
  $\sigma_{xyz} = sdv(a_{uv})$\;  
 }
 sort by $\sigma_{xyz}$ in increasing order\;
 \tcc{select greedy}
 \If{$\bar{a}_{xyz} \in [0,1]$}{accept\;}
 \If{$-\sigma_{xyz} < \bar{a}_{xyz} < 0 $}{accept\;}
 \If{$1 < \bar{a}_{xyz} < 1+\sigma_{xyz}$}{accept\;}
 
 \tcc{now we know the best $\{x,y,z\}$ and need to remove $z$}
 
 \For{$\{u,v\} \in V\setminus\{x,y,z\}$}{
 
   \If{$\forall a_{u,v}: a_{u,v}=a\in [0,1]$}{
   \eIf{$a \neq 0,1$}{
   $\delta_z = \frac{1}{2}(d'_{xz}+d'_{yz}-d'_{xy})$\;
   $d_{xy} = $ \TODO{siehe Gleichung 11}\;
   $\delta_x = d'_{xz} - (1-a)*d_{xy} - \delta_z$\;
   $\delta_y = d'_{yz} - a*\delta_z$\;
  }{
   \If{$\bar{a}_{xyz} < 0$} {accept $\bar{a}_{xyz} = 0$\;}
   \If{$\bar{a}_{xyz} > 1$} {accept $\bar{a}_{xyz} = 1$\;}
  }
  $\forall p,q\in V\setminus\{x,y,z\}, p\neq q: d_{pq} = d_{pq}-\delta_p-\delta_q$\;
  delete row and column $z$ form $D$\;
  }
  }
\end{algorithm}

\begin{enumerate}
 \item \TODO{check whether all brackets are correctly set} \\
 \item \TODO{check whether $d_{xy}$ 
  conforms to the triangle inequality $d_{xy} \leq d_{ux} + d_{uy}$?} \\
 \item \TODO{Wenn Baum, haben wir das richtige Ergebnis? (sanity check) Was passiert bei Cherries?} \\
 \item \TODO{NR: Test on simulated noisy data} \\
 \item \TODO{put somewhere: $\forall d,\delta: d,\delta\geq 0$, otherwise: $d,\delta = 0$}
\end{enumerate}





\subsection*{Special Cases} 

Recognizing the special cases $a =0$ and $a =1$, respectively.

Equ.(9) of \cite{Prohaska:17a} implies that $a=0$ iff 
$d'_{uz}-d'_{vz} = d'_{uy}-d'_{vy}$ for all $y$ and $a=1$ iff 
$d'_{uz}-d'_{vz} = d'_{ux}-d'_{vx}$.

It makes sense therefore, to capture these cases upfront. In fact the two
cases are effectively the same, identifying $y$ and $x$, respectively, as
the sole ancestral branches, corresponds to a tree-like speciation. 

In this case we know that $d'_{xz}=\delta_x+\delta_z$ and 
$d'_{ux}-d'_{uz}=\delta_x-\delta_z$, whence 
$d'_{xz}+d'_{ux}-d'_{uz}=2\delta_x$
and 
$d'_{xz}+d'_{uz}-d'_{ux}=2\delta_y$. 
For numerical stability it is advisable to first compute 
\begin{equation} 
  C := \frac{1}{|V|-2} \sum_{u\in V\setminus\{x,y\}} (d'_{ux}-d'_{uz})
\end{equation} 
and then choose the consensus value $2\delta_x = d'_{xz}+C$ and 
$2\delta_x = d'_{xz}-C$.



\begin{algorithm}[H]
\caption{alg:Tree-Like-Step}
 \SetAlgoLined
 \For{$\{x,z\} \subseteq V$}{
   \For{$\{u,v\}\in V\setminus\{x,z\}$}{ 
     $\epsilon_{xz} += \Vert (d_{vz}-d_{uz})- (d_{vx}-d_{ux}) \Vert$\;
   }   
 }
 Determine minimum of $\epsilon_{xz}$;
 \If{$\epsilon_{xz}<\varepsilon$}{
   compute $C$, $\delta_x$, $\delta_z$ as above\;
   record ``divergence of $(x,z)$ with $\delta_z$ and $\delta_z$''\;
 \For{$u\in V\setminus\{x\}$}{
   $d_{ux} \leftarrow  d_{ux}-\delta_x$\;} 
 }
\end{algorithm}


\bibliographystyle{abbrv}      
\bibliography{hybrid}   

\end{document}
