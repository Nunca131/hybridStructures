\documentclass{article}

\usepackage{xcolor}
\usepackage{algorithm2e}
\usepackage{algorithmic}
\usepackage{amsmath}


\newcommand{\TODO}[1]{\begingroup\color{red}#1\endgroup}
\newcommand{\NR}[1]{\begingroup\color{orange}#1\endgroup}
\newcommand{\PFS}[1]{\begingroup\color{green}#1\endgroup}



\begin{document}

\title{\TODO{some fancy title}}

\maketitle


\begin{abstract}
 some cool abstract
\end{abstract}

\section{Introduction}

\begin{itemize}
 \item evolution of gene clusters as in~\cite{Prohaska:17a}
 \item evolutionary events considered where either duplication 
 or recombination events (since losses cannot be observed when 
 we there is only one species under consideration)
 \item recombination events can happen due to unequal crossing
 over during mitosis
 \item if the breakpoint is in a gene, the resulting gene is
 a recombinant of its two parent genes ($x$ and $y$) who are
 considered to be adjacent
 \item here: lifting adjacency constraint of ''recombination''
 \item application to languages: e.g. English lexicon is said
 to contain 29\% Latin and as well as 29\% French words that 
 did not derive from its Germanic root which only contributes 
 with 25\%~\cite{Finkenstaedt:73}.
\end{itemize}


\section{R-Metrics} 

In~\cite{Prohaska:17a} we introduced R-metrics by means of a simple
iterative scheme starting from a pair of points $\{x,y\}$ with a given
distance $d_{xy}$.  First, an additional point $z$ is inserted as a
``mixture'' of two parents $x$ and $y$ with a mixture ratio $a$. We assume
that the distance of $d_{zu}$ correspondinly is a mixture of $d_{xu}$ and
$d_{yu}$. More precisely, we assume that
\begin{equation} 
\begin{split} 
  d_{zx} & = (1-a)  d_{xy} \\
  d_{zy} & =   a    d_{xy} \\
  d_{zu} & =   a    d_{xu} + (1-a)  d_{yu} \quad\textrm{for all}\ 
                     u\in V\setminus\{ x,y \}
\end{split}
\end{equation} 
Then all points diverge with arbitrary rates, i.e., 
\begin{equation} 
  d_{pq}' = d_{pq} + \delta_p + \delta_q \quad\textrm{for all}\ 
  p,q \in V\cup\{z\} 
\end{equation} 
We say that a metric is an R-metric if it can be constructed in this
manner.


\subsection*{Properties of R-metrics} 


\TODO{It does not seem to be very easy to check whether R-metric are 
totally decomposable or not. There is a reasonably easy 5-point condition
for that, however:

Set 
\begin{equation} 
  \alpha(tu|vw) := 
  \max\left\{ d_{tu}+d_{vw}, d_{tv}+d_{uw}, d_{tw}+d_{vu} \right\} -
             (d_{tu}+d_{vw})
\end{equation} 

Then Thm.6 of \cite{Bandelt:92} states that the metric is \emph{totally
  decomposable} iff and only if for all $t,u,v,w,x\in V$ holds 
\begin{equation} 
  \alpha(tu|vw) \le \alpha(tx|vw)+\alpha(tu|vx)
\end{equation} 

CAN YOU PLEASE CHECK THIS NUMBERICALLY as a first step. If we see that the 
R-metrics are totally decomposable in a large number of randomly generated
examples it will be worth while to show that analytically, presumably by 
proving that our construction the inequality above whenever.
}

\subsection{From Recognition to Approximation} 

In \cite{Prohaska:17a} we described an $O(|V|^5)$ algorithm to recognize 
R-metrics.    




\begin{algorithm}[H]
\caption{Old recognition algorithm for R matrices}
\SetAlgoLined
\For{$\{x,y,z\} \in V$}{
  \For{$\{u,v\} \in V\setminus\{x,y,z\}$}{
   $a_{u,v} := 
   \frac{(d'_{uz}+d'_{vy})-(d'_{vz}+d'_{uy})}{(d'_{ux}+d'_{vy})-(d'_{vx}+d'_{uy})}$\;
  }
  \If{$\forall a_{u,v}: a_{u,v}=a\in [0,1]$}{
   \eIf{$a \neq 0,1$}{
   $\delta_z = \frac{1}{2}(d'_{xz}+d'_{yz}-d'_{xy})$\;
   $d_{xy} = \frac{(d'_{uz}-a*d'_{ux}-(1-a)*d'_{uy})-2*\delta_z + a*d'_{xz}+(1-a)*d'_{yz}}{2a(1-a)}$\;
   $\delta_x = d'_{xz} - (1-a) d_{xy} - \delta_z$\;
   $\delta_y = d'_{yz} - a \delta_z$\;
  }{
   \TODO{$a=0,a=1$ what happens then?}\;
  }
  \PFS{$\forall u\in V\setminus\{x,y,z\}$ and $\forall p\in\{x,y\}$ set   
  $d_{up} = d_{pu} -\delta_p$\;
  \TODO{note that $\delta_u=0$ for $u\in V\setminus\{x,y,z\}$}}
  delete row and column $z$ form $D$\;
  }  
}
\end{algorithm}

We note that in each merge step we have $\delta_u=0$ for all $u\in
V\setminus\{x,y,z\}$ 



\begin{algorithm}[H]
\caption{Top level recursion}
 \SetAlgoLined
 \While{$|V|\ge 4$}{ 
   determine best tree-like step $(x,z)\to x$\;
   determine best merge step $(x,z,y)\to(x,y)$\;
   perform the better of tree-like or merge step\;
   remove $z$ from $\mathbf{D}$ and $V$ 
 }
 compute initial tree for $|V|\le 3$ leaves\;
\end{algorithm} 
   
 

\begin{algorithm}[H]
\caption{Approximation recognition algorithm for R matrices}
 \SetAlgoLined
 \For{$\{x,y,z\} \in V$}{
  \For{$\{u,v\} \in V\setminus\{x,y,z\}$}{
   $a_{u,v} := \frac{(d'_{uz}+d'_{vy})-(d'_{vz}+d'_{uy})}{(d'_{ux}+d'_{vy})-(d'_{vx}+d'_{uy})}$\;
  }
  $\bar{a}_{xyz} = \frac{2}{(n-3)(n-4)} * a_{uv}$\;
  $\sigma_{xyz} = sdv(a_{uv})$\;  
 }
 sort by $\sigma_{xyz}$ in increasing order\;
 \tcc{select greedy}
 \If{$\bar{a}_{xyz} \in [0,1]$}{accept\;}
 \If{$-\sigma_{xyz} < \bar{a}_{xyz} < 0 $}{accept\;}
 \If{$1 < \bar{a}_{xyz} < 1+\sigma_{xyz}$}{accept\;}
 
 \tcc{now we know the best $\{x,y,z\}$ and need to remove $z$}
 
 \For{$\{u,v\} \in V\setminus\{x,y,z\}$}{
 
   \If{$\forall a_{u,v}: a_{u,v}=a\in [0,1]$}{
   \eIf{$a \neq 0,1$}{
   $\delta_z = \frac{1}{2}(d'_{xz}+d'_{yz}-d'_{xy})$\;
   $d_{xy} = \frac{(d'_{uz}-a*d'_{ux}-(1-a)*d'_{uy})-2*\delta_z + a*d'_{xz}+(1-a)*d'_{yz}}{2a(1-a)}$\;
   $\delta_x = d'_{xz} - (1-a)*d_{xy} - \delta_z$\;
   $\delta_y = d'_{yz} - a*\delta_z$\;
  }{
   \If{$\bar{a}_{xyz} < 0$} {accept $\bar{a}_{xyz} = 0$\;}
   \If{$\bar{a}_{xyz} > 1$} {accept $\bar{a}_{xyz} = 1$\;}
  }
  \NR{$\forall p,q\in V, p =\{x,y\}: d_{pq} = d_{pq}-\delta_p$}\;
  }
  }
\end{algorithm}

\begin{enumerate}
 \item \TODO{check whether all brackets are correctly set} \\
 \item \TODO{check whether $d_{xy}$ 
  conforms to the triangle inequality $d_{xy} \leq d_{ux} + d_{uy}$?} \\
 \item \TODO{Wenn Baum, haben wir das richtige Ergebnis? (sanity check) Was passiert bei Cherries?} \\
 \item \TODO{NR: Test on simulated noisy data} \\
 \item \TODO{put somewhere: $\forall d,\delta: d,\delta\geq 0$, otherwise: $d,\delta = 0$}
\end{enumerate}





\subsection*{Special Cases} 

Recognizing the special cases $a =0$ and $a =1$, respectively.

Equ.(9) of \cite{Prohaska:17a} implies that $a=0$ iff 
$d'_{uz}-d'_{vz} = d'_{uy}-d'_{vy}$ for all $y$ and $a=1$ iff 
$d'_{uz}-d'_{vz} = d'_{ux}-d'_{vx}$.

It makes sense therefore, to capture these cases upfront. In fact the two
cases are effectively the same, identifying $x$ and $y$, respectively, as
the sole ancestral branches, corresponds to a tree-like speciation. 

In this case we know that $d'_{xz}=\delta_x+\delta_z$ and 
$d'_{ux}-d'_{uz}=\delta_x-\delta_z$, whence 
$d'_{xz}+d'_{ux}-d'_{uz}=2\delta_x$
and 
$d'_{xz}+d'_{uz}-d'_{ux}=2\delta_y$. 
For numerical stability it is advisable to first compute 
\begin{equation} 
  C := \frac{1}{|V|-2} \sum_{u\in V\setminus\{x,y\}} (d'_{ux}-d'_{uz})
\end{equation} 
and then choose the consensus value $2\delta_x = d'_{xz}+C$ and 
$2\delta_x = d'_{xz}-C$.



\begin{algorithm}[H]
\caption{\NR{Cherry picking}}
\label{alg:cherries}
 \SetAlgoLined
 \For{$\{x,z\} \subseteq V$}{
   \For{$\{u,v\}\in V\setminus\{x,z\}$}{ 
     $\epsilon_{xz} += \Vert (d_{vz}-d_{uz})- (d_{vx}-d_{ux}) \Vert$\;
   }   
 }
 Determine minimum of $\epsilon_{xz}$;
 \If{$\epsilon_{xz}<\varepsilon$}{
   compute $C$, $\delta_x$, $\delta_z$ as above\;
   record ``divergence of $(x,z)$ with $\delta_z$ and $\delta_z$''\;
 \For{$u\in V\setminus\{x\}$}{
   $d_{ux} =  d_{ux}-\delta_x$\;} 
 }
\end{algorithm}





\bibliographystyle{abbrv}      
\bibliography{hybrid}   

\end{document}
